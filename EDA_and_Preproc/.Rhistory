if(length(result)!=0){
write.csv(result, path, row.names = FALSE)
} else {
fname = NULL
}
return(fname)
}
lst_fnames = character()
four_quarters = paste("Q", 1:4, sep = "")
for(year in 2009:2019){
for(quarter in four_quarters){
i = length(lst_fnames) + 1
fname = load_file_get_fname(year, quarter)
if(length(fname)!=0){
lst_fnames[i] = fname
}
}
}
write(lst_fnames, file = "~/Desktop/data/lst_fnames.txt", sep = ',')
library (RCurl)
library (RCurl)
shiny::runApp('Desktop/Shiny App/NOAA_app')
runApp('Desktop/Shiny App/NOAA_app')
runApp('Desktop/Shiny App/NOAA_app')
runApp('Desktop/Shiny App/NOAA_app')
runApp('Desktop/Shiny App/NOAA_app')
runApp('Desktop/Shiny App/NOAA_app')
runApp('Desktop/Shiny App/NOAA_app')
runApp('Desktop/Shiny App/NOAA_app')
runApp('Desktop/Shiny App/NOAA_app')
runApp('Desktop/Shiny App/NOAA_app')
shiny::runApp('Desktop/NYCDSA/Shiny App/NOAA_app')
brewer.all()
display.brewer.all()
runApp('Desktop/NYCDSA/Shiny App/NOAA_app')
coul -> brewer.pal(9), "Reds")
coul -> brewer.pal(9, "Reds")
coul = brewer.pal(9, "Reds")
colorRampPalette(coul)(15)
coul
runApp('Desktop/NYCDSA/Shiny App/NOAA_app')
runApp('Desktop/NYCDSA/Shiny App/NOAA_app')
data(HairEyeColor)
datasets::(HairEyeColor)
datasets::HairEyeColor
importIntoEnv(HairEyeColor)
head(HairEyeColor)
#1
mosaicplot(HairEyeColor, shade = TRUE)
datasets::HairEyeColor
HairEyeColor %>%
filter(Sex == Female & Eye == brown | blue)
title: "Foundations_of_Stats_Homework"
author: "NYC Data Science Academy"
output: html_document
---
library(pander)
library(ggplot2)
library(dplyr)
library(plyr)
## Question #1: Body Temperature
g
title: "Foundations_of_Stats_Homework"
author: "NYC Data Science Academy"
output: html_document
---
library(pander)
library(ggplot2)
library(dplyr)
library(plyr)
title: "Foundations_of_Stats_Homework"
author: "NYC Data Science Academy"
output: html_document
---
library(pander)
library(ggplot2)
library(dplyr)
library(plyr)
HairEyeColor %>%
filter(Sex == Female & Eye == brown | blue)
setDF(HairEyeColor)
library(data.table)
setDF(HairEyeColor)
#1
mosaicplot(HairEyeColor, shade = TRUE)
x <- apply(HairEyeColor, c(1, 2), sum)
## More than expected : blond and brown,
x
library(data.table)
datasets::HairEyeColor
#1
mosaicplot(HairEyeColor, shade = TRUE)
x <- apply(HairEyeColor)
x <- apply(HairEyeColor, sum)
## More than expected : blond and brown,
x <- apply(HairEyeColor, Sex)
## More than expected : blond and brown,
x <- apply(HairEyeColor, Sex == F)
## More than expected : blond and brown,
x <- apply(HairEyeColor, Sex == F, sum)
#1
mosaicplot(HairEyeColor, shade = TRUE)
data("HairEyeColor")
as.data.frame('HairEyeColor')
as.data.frame("HairEyeColor")
data("HairEyeColor")
#1
mosaicplot(HairEyeColor, shade = TRUE)
#2
sum(HairEyeColor$Freq)
#2
subset(HairEyeColor, Sex == Female)
#1
mosaicplot(HairEyeColor, shade = TRUE)
#2
head(HairEyeColor)
#2
HairEyeColor
summary(aov(PlantGrowth$weight ~ PlantGrowth$group))
title: "Foundations_of_Stats_Homework"
author: "NYC Data Science Academy"
output: html_document
---
library(pander)
library(ggplot2)
library(dplyr)
library(plyr)
title: "Foundations_of_Stats_Homework"
author: "NYC Data Science Academy"
output: html_document
---
library(pander)
library(ggplot2)
library(dplyr)
library(plyr)
title: "Foundations_of_Stats_Homework"
author: "NYC Data Science Academy"
output: html_document
---
library(pander)
library(ggplot2)
library(dplyr)
library(plyr)
title: "Foundations_of_Stats_Homework"
author: "NYC Data Science Academy"
output: html_document
---
library(pander)
library(ggplot2)
library(dplyr)
library(plyr)
temp = read.table('https://s3.amazonaws.com/graderdata/Temp.txt', header = TRUE)
#5
var.test(temp$Body.Temp ~ temp$Gender)
data(PlantGrowth)
head(PlantGrowth, 5)
#1
ggplot(data = PlantGrowth, aes(x = group, y = weight)) +
geom_boxplot()
#2
levels(PlantGrowth$group)
ddply(PlantGrowth,~group,summarise,mean=mean(weight),sd=sd(weight))
summary(aov(PlantGrowth$weight ~ PlantGrowth$group))
bartlett.test(PlantGrowth$weight ~ PlantGrowth$group)
ddply(PlantGrowth,~group,summarise,mean=mean(weight),sd=sd(weight))
bartlett.test(PlantGrowth$weight ~ PlantGrowth$group)
#3
# based on the bartlett test, do not reject the NULL. There
# is not a significant difference in variance in weight
# across the different grops
data("HairEyeColor")
mosaicplot(HairEyeColor[,1:2,2],shade = T)
# More: Black hair and brown eye. Blond hair and blue eye.
# Fewer: Blue eye and black hair. Brown hair and blue eye. Blond hair and brown eye.
chisq.test(HairEyeColor[,1:2,2])
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
install.packages('HSAUR')
library(HSAUR)
heptathlon
data = heptathlon
library(ggplot2)
View(data)
plotmatrix(with(data, data.frame(hurdles, highjump, shot, run200m, longjump, javelin, run800m, score )))
library(ggplot2)
plotmatrix(with(data, data.frame(hurdles, highjump, shot, run200m, longjump, javelin, run800m, score )))
plot(data)
return(x - max(data$score))
return( max(data$score)-x)
####################################################### TEMPERATURE
##### converting degrees C into F function
to_f = function(x){
rnge = range(x, na.rm = TRUE)
return(x * (9/5) + 32)
}
rng = range(x, na.rm = TRUE)
trans_ = function(x){
return( max(data$score) - x)
}
trans_(data$hurdles)
data$hurdles = trans_(data$hurdles)
data$run200m = trans_(data$run200m)
data$run800m = trans_(data$run800m)
plot(data)
install.packages('psych')
llibrary(psych)
library(psych)
library(dplyr)
data2 = data %>%
filter(hurdles, highjump,shot, run200m,longjump, javelin,run800m)
fa.parallel(data2,
n.obs = 25,
fa = 'pc',
n.iter = 100)
abline(h = 1)
fa.parallel(data2,
n.obs = 25,
fa = 'pc',
n.iter = 100)
fa.parallel(data2,
n.obs = 25,
fa = 'pc',
n.iter = 100)
fa.parallel(data2,
n.obs = 25,
fa = 'pc',
n.iter = 100)
#######################
#####Tools for PCA#####
#######################
library(psych) #Library that contains helpful PCA functions, such as:
principal() #Performs principal components analysis with optional rotation.
fa.parallel() #Creates scree plots with parallell analyses for choosing K.
factor.plot() #Visualizes the principal component loadings.
############################
#####Data for Example 1#####
############################
bodies = Harman23.cor$cov #Covariance matrix of 8 physical measurements on 305 girls.
bodies
####################
#####Choosing K#####
####################
fa.parallel(bodies, #The data in question.
n.obs = 305, #Since we supplied a covaraince matrix, need to know n.
fa = "pc", #Display the eigenvalues for PCA.
n.iter = 100) #Number of simulated analyses to perform.
abline(h = 1) #Adding a horizontal line at 1.
abline(h = 1)
fa.parallel(data2,
n.obs = 25,
fa = 'pc',
n.iter = 100)
abline(h = 1)
fa.parallel(data2,
n.obs = 25,
fa = 'pc',
n.iter = 100)
install.packages(c("psych", "Sleuth2"))
install.packages(c("psych", "Sleuth2"))
####################
#####Choosing K#####
####################
fa.parallel(bodies, #The data in question.
n.obs = 305, #Since we supplied a covaraince matrix, need to know n.
fa = "pc", #Display the eigenvalues for PCA.
n.iter = 100) #Number of simulated analyses to perform.
#######################
#####Tools for PCA#####
#######################
library(psych) #Library that contains helpful PCA functions, such as:
principal() #Performs principal components analysis with optional rotation.
fa.parallel() #Creates scree plots with parallell analyses for choosing K.
factor.plot() #Visualizes the principal component loadings.
############################
#####Data for Example 1#####
############################
bodies = Harman23.cor$cov #Covariance matrix of 8 physical measurements on 305 girls.
bodies
####################
#####Choosing K#####
####################
fa.parallel(bodies, #The data in question.
n.obs = 305, #Since we supplied a covaraince matrix, need to know n.
fa = "pc", #Display the eigenvalues for PCA.
n.iter = 100) #Number of simulated analyses to perform.
########################
#####Performing PCA#####
########################
pc_bodies = principal(bodies, #The data in question.
nfactors = 2, #The number of PCs to extract.
rotate = "none")
pc_bodies
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
pc_data2= principal(data2, #The data in question.
nfactors = 2, #The number of PCs to extract.
rotate = "none")
pc_data2
plot(pc_data2)
factor.plot(pc_data2,
labels = colnames(data2))
########################################
#####Visualizing & Interpreting PCA#####
########################################
factor.plot(pc_bodies,
labels = colnames(bodies)) #Add variable names to the plot.
View(data2)
View(data2)
head(data2)
data2 = data %>%
filter(hurdles, highjump,shot, run200m,longjump, javelin,run800m)
library(dplyr)
data2 = data %>%
filter(hurdles, highjump,shot, run200m,longjump, javelin,run800m)
data2 = data %>%
filter(hurdles, highjump,shot, run200m,longjump, javelin,run800m)
data2
data2 = data.frame(data$hurdles, data$highjump,data$shot, data$run200m,data$longjump, data$javelin,data$run800m)
head(data2)
head(data2)
fa.parallel(data2,
n.obs = 25,
fa = 'pc',
n.iter = 100)
pc_data2= principal(data2, #The data in question.
nfactors = 2, #The number of PCs to extract.
rotate = "none")
pc_data2
factor.plot(pc_data2,
labels = colnames(data2))
plot(data$score)
factor.plot(data$score)
plot(data$score)
biplot(score.pca)
biplot(pc_data2)
library(dplyr)
library(survey)
library(tidyr)
library(knitr)
library(questionr)
library(stargazer)
library(mlbench)
library(caret)
library(carData)
library(MASS)
library(caTools)
library(randomForest)
options(max.print=100000)
cdc_data2 = read.csv('survey_answers.csv')
setwd("~/Desktop/Capstone_Proj/EDA_and_Preproc")
cdc_data2 = read.csv('survey_answers.csv')
head(cdc_data2)
sum(is.na(cdc_data2))
colnames(cdc_data2)
cdc_split = sample.split(cdc_data2,SplitRatio = 0.3)
train = subset(cdc_data2,cdc_split==TRUE)
test = subset(cdc_data2,cdc_split==FALSE)
####### Survey
############## data with Non missing weights
options(survey.lonely.psu = "adjust")
## Survey design
des = svydesign(ids=~1, strata=~stratum, weights=~weight, data = cdc_data2[is.na(cdc_data2$weight) == F,])
des2 = svydesign(ids=~1, strata=~stratum, weights=~weight, data = train[is.na(train$weight) == F,])
des3 = svydesign(ids=~1, strata=~stratum, weights=~weight, data = test[is.na(test$weight) == F,])
svymean(~weapons_all, des)
colnames(cdc_data2)
### TRAIN full #######################
glm.red_full = svyolr(weapons_all~. -X-psu-weight-stratum-weapons_toschool-weapons_gun, data = train)
### TRAIN full #######################
glm.red_full = svyolr(weapons_all~. -X-psu-weight-stratum-weapons_toschool-weapons_gun, des2)
summary(olr.red_full)
### TRAIN full #######################
olr.red_full = svyolr(weapons_all~. -X-psu-weight-stratum-weapons_toschool-weapons_gun, des2)
### TRAIN full #######################
olr.red_full = svyolr(weapons_all~. -X-psu-weight-stratum-weapons_toschool-weapons_gun, design = des2)
library(dplyr)
library(dplyr)
library(tidyr)
cdc_data = read.csv('cdc_data_noNA.csv')
cdc_QN = read.csv('weighted_2017.csv')
cdc_data2 = read.csv('survey_answers.csv')
setwd("~/Desktop/Capstone_Proj/DATA")
cdc_QN = read.csv('weighted_2017.csv')
head(cdc_data2)
head(cdc_QN)
sum(is.na(cdc_QN$QN12))
cdc_weapon = data.frame(cdc_QN$QN12, cdc_QN$QN13, cdc_QN$QN14)
names(cdc_weapon) <- c("weapon", "w_toschool", "gun")
head(cdc_weapon)
cdc_data2 = cbind(cdc_weapon, cdc_data2)
head(cdc_data2)
sum(is.na(cdc_data2$gun))
unique(cdc_data2$gun)
val <- unique(cdc_data2[!is.na(cdc_data2)])
mode <- val[which.max(tabulate(match(cdc_data2, val)))]
cdc_data2[is.na(cdc_data2)] <- mode
sum(is.na(cdc_data2))
write.csv(cdc_data2, "survey_answers.csv")
library(dplyr)
library(survey)
library(tidyr)
library(knitr)
library(questionr)
library(stargazer)
library(mlbench)
library(caret)
library(carData)
library(MASS)
library(caTools)
library(randomForest)
options(max.print=100000)
cdc_data2 = read.csv('survey_answers.csv')
head(cdc_data2)
colnames(cdc_data2)
cdc_split = sample.split(cdc_data2,SplitRatio = 0.3)
train = subset(cdc_data2,cdc_split==TRUE)
test = subset(cdc_data2,cdc_split==FALSE)
####### Survey
############## data with Non missing weights
options(survey.lonely.psu = "adjust")
## Survey design
des = svydesign(ids=~1, strata=~stratum, weights=~weight, data = cdc_data2[is.na(cdc_data2$weight) == F,])
des2 = svydesign(ids=~1, strata=~stratum, weights=~weight, data = train[is.na(train$weight) == F,])
des3 = svydesign(ids=~1, strata=~stratum, weights=~weight, data = test[is.na(test$weight) == F,])
svymean(~weapons_all, des)
colnames(cdc_data2)
##### Models
set.seed(7)
### TRAIN full #######################
olr.red_full = svyolr(weapons_all~. -X-psu-weight-stratum-weapons_toschool-weapons_gun, design = des2)
### TRAIN full #######################
olr.red_full = svyolr(weapons_all~. -X-psu-weight-stratum, design = des2)
### TRAIN full #######################
olr.red_full = svyolr(weapons_all~. -X-psu-weight-stratum, des2)
### TRAIN full #######################
olr.red_full = svyolr(weapons_all~. -X-psu-weight-stratum-X.1-w_toschool-gun, des2)
library(dplyr)
library(survey)
library(tidyr)
library(knitr)
library(questionr)
library(stargazer)
library(mlbench)
library(caret)
library(carData)
library(MASS)
library(caTools)
library(randomForest)
options(max.print=100000)
cdc_data2 = read.csv('survey_answers.csv')
head(cdc_data2)
sum(is.na(cdc_data2))
colnames(cdc_data2)
cdc_split = sample.split(cdc_data2,SplitRatio = 0.3)
train = subset(cdc_data2,cdc_split==TRUE)
test = subset(cdc_data2,cdc_split==FALSE)
## Survey design
des = svydesign(ids=~1, strata=~stratum, weights=~weight, data = cdc_data2[is.na(cdc_data2$weight) == F,])
svymean(~weapons_all, des)
svymean(~weapons_all, des)
##### Models
set.seed(7)
des2 = svydesign(ids=~1, strata=~stratum, weights=~weight, data = train[is.na(train$weight) == F,])
des3 = svydesign(ids=~1, strata=~stratum, weights=~weight, data = test[is.na(test$weight) == F,])
### TRAIN full #######################
olr.red_full = svyolr(weapons_all~. -X-psu-weight-stratum-X.1-w_toschool-gun, design = des2)
### TRAIN full #######################
olr.red_full = svyolr(weapons_all~. -X-psu-weight-stratum-X.1, design = des2)
### TRAIN full #######################
glm.red_full = svyglm(weapon~. -X-psu-weight-stratum-X.1, design = des2)
### TRAIN full #######################
glm.red_full = svyglm(weapon~., design = des2)
### TRAIN full #######################
glm.red_full = svyglm(weapon~., des2)
### TRAIN full #######################
glm.red_full = svyglm(weapon~ raceeth, des2)
summary(olr.red_full)
summary(glm.red_full)
### TRAIN full #######################
glm.red_full = svyglm(weapon~ . +raceeth + Sex + sex_id , des2)
colnames(train)
### TRAIN full #######################
olr.red_full = svyolr(weapons_all~ ., des2)
### TRAIN full #######################
olr.red_full = svyolr(weapons_all~. -psu-stratum-X-X.1, des2)
head(cdc_data2)
setwd("~/Desktop/Capstone_Proj/EDA_and_Preproc")
cdc_data2 = read.csv('cdc_data_noNA.csv')
cdc_data = read.csv('cdc_data_noNA.csv')
head(cdc_data)
## removing index variable X from python clean
cdc_data =  select(cdc_data, -1, -3)
head(cdc_data)
## removing index variable X from python clean
cdc_data =  select(cdc_data, -1, -3)
head(cdc_data)
## removing index variable X from python clean
cdc_data =  select(cdc_data, -1, -3)
## removing index variable X from python clean
select(cdc_data, -1, -3)
## removing index variable X from python clean
cdc_data = select(cdc_data, -1, -3)
library(dplyr)
library(tidyr)
cdc_data = read.csv('cdc_data_noNA.csv')
head(cdc_data)
## removing index variable X from python clean
cdc_data = select(cdc_data, -1, -3)
## removing index variable X from python clean
cdc_data = select(cdc_data, -1, -3)
## removing index variable X from python clean
cdc_data = select(cdc_data, -1, -3)
## removing index variable X from python clean
cdc_data2 = select(cdc_data, -1, -3)
